{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fundamentals of Py Tourch**\n",
    "- `Resource Note Book` : [Resource Notebook](https://www.learnpytorch.io/00_pytorch_fundamentals/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "### Introduction To Tensor\n",
    "\n",
    "#### Creating Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "# scalar\n",
    "scalar = torch.tensor(7)\n",
    "print(scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "dimention_of_tensor=scalar.ndim\n",
    "print(dimention_of_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "### Get tensor back as python Int\n",
    "item_in_tensor=scalar.item()\n",
    "print(item_in_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "### Vector\n",
    "vector = torch.tensor([1, 2, 3])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "### vector Dimension\n",
    "dimention_of_tensor=vector.ndim\n",
    "print(dimention_of_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "### shape of the tensor\n",
    "tensor_shape  = vector.shape\n",
    "print(tensor_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "#   MATRIX\n",
    "MATRIX = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(MATRIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "dimention_of_tensor = MATRIX.ndim\n",
    "print(dimention_of_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "shape_of_tensor=MATRIX.shape\n",
    "print(shape_of_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "print(MATRIX[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]],\n",
      "\n",
      "        [[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n"
     ]
    }
   ],
   "source": [
    "# TENSOR\n",
    "TENSOR = torch.tensor([[[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]], [[1, 2, 3], [4, 5, 6], [7, 8, 9]]])\n",
    "print(TENSOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# dimension of the tensor\n",
    "dimention_of_tensor = TENSOR.ndim\n",
    "print(dimention_of_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# shape of the tensor\n",
    "shape_of_tensor = TENSOR.shape\n",
    "print(shape_of_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Tensors\n",
    "- `why Random Tensors?`\n",
    "- `Random Tensors` are important because the way many neural networks learns is that they start with tensors full of random numbers and then adjust the numbers to get to better representations of the data.\n",
    "\n",
    "`start with random numbers -> look at the daat -> update the random numbers -> look at the data -> update the random numbers`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8573, 0.8695, 0.6584]) \n",
      "\n",
      "tensor([[0.0137, 0.2160, 0.6846, 0.6053],\n",
      "        [0.0383, 0.4277, 0.2673, 0.6275],\n",
      "        [0.4148, 0.1008, 0.4428, 0.1574]]) \n",
      "\n",
      "tensor([[[0.3227, 0.7477, 0.2893, 0.1450, 0.2327],\n",
      "         [0.1681, 0.4584, 0.6166, 0.9294, 0.8973],\n",
      "         [0.3817, 0.4783, 0.3715, 0.0868, 0.0258],\n",
      "         [0.5055, 0.8391, 0.4051, 0.0537, 0.3800]],\n",
      "\n",
      "        [[0.4414, 0.4638, 0.5818, 0.6957, 0.8388],\n",
      "         [0.2378, 0.4486, 0.9509, 0.3383, 0.0340],\n",
      "         [0.9301, 0.3331, 0.1141, 0.7130, 0.7564],\n",
      "         [0.6998, 0.7915, 0.7777, 0.7416, 0.1787]],\n",
      "\n",
      "        [[0.2900, 0.2431, 0.6604, 0.3881, 0.6860],\n",
      "         [0.8744, 0.8148, 0.9859, 0.3594, 0.8508],\n",
      "         [0.4375, 0.6035, 0.8534, 0.4687, 0.7063],\n",
      "         [0.1882, 0.0512, 0.3985, 0.4280, 0.8007]]]) \n",
      "\n",
      "tensor([[[[0.3751, 0.2809, 0.9818, 0.2421, 0.8181, 0.1449],\n",
      "          [0.3819, 0.9787, 0.2511, 0.1918, 0.5582, 0.4199],\n",
      "          [0.0236, 0.9274, 0.5721, 0.7735, 0.9267, 0.9164],\n",
      "          [0.0521, 0.2305, 0.4164, 0.2607, 0.2099, 0.1608],\n",
      "          [0.8407, 0.5722, 0.0985, 0.9194, 0.9895, 0.6877]],\n",
      "\n",
      "         [[0.5280, 0.3043, 0.5391, 0.7058, 0.5440, 0.5049],\n",
      "          [0.0471, 0.9194, 0.7742, 0.2495, 0.7100, 0.8435],\n",
      "          [0.8644, 0.1558, 0.1670, 0.5120, 0.2303, 0.0361],\n",
      "          [0.0719, 0.4530, 0.2875, 0.7699, 0.2140, 0.7490],\n",
      "          [0.5651, 0.5351, 0.0047, 0.0931, 0.1007, 0.8788]],\n",
      "\n",
      "         [[0.4638, 0.1508, 0.8792, 0.1485, 0.4953, 0.4525],\n",
      "          [0.9909, 0.2139, 0.3687, 0.4453, 0.8491, 0.7494],\n",
      "          [0.6761, 0.8654, 0.2437, 0.0413, 0.3495, 0.9034],\n",
      "          [0.9809, 0.1977, 0.9238, 0.2668, 0.2326, 0.6430],\n",
      "          [0.4443, 0.9464, 0.3024, 0.3443, 0.8130, 0.0703]],\n",
      "\n",
      "         [[0.8577, 0.5903, 0.1504, 0.1175, 0.5614, 0.9621],\n",
      "          [0.6847, 0.4180, 0.9856, 0.9366, 0.8654, 0.9759],\n",
      "          [0.2453, 0.4174, 0.5549, 0.0841, 0.0050, 0.5819],\n",
      "          [0.1803, 0.2737, 0.7446, 0.0990, 0.9533, 0.6958],\n",
      "          [0.1167, 0.6971, 0.2908, 0.9645, 0.0887, 0.4659]]],\n",
      "\n",
      "\n",
      "        [[[0.7891, 0.7857, 0.0982, 0.2636, 0.2229, 0.0924],\n",
      "          [0.3048, 0.6070, 0.7741, 0.9858, 0.9149, 0.9480],\n",
      "          [0.3089, 0.1996, 0.5191, 0.3421, 0.3973, 0.0076],\n",
      "          [0.5485, 0.4755, 0.0933, 0.8481, 0.3289, 0.0595],\n",
      "          [0.3888, 0.9800, 0.8818, 0.3659, 0.6070, 0.3519]],\n",
      "\n",
      "         [[0.3547, 0.1004, 0.6787, 0.2371, 0.3122, 0.0019],\n",
      "          [0.1721, 0.3134, 0.7862, 0.9965, 0.9102, 0.8633],\n",
      "          [0.0614, 0.3684, 0.8553, 0.5576, 0.8671, 0.6641],\n",
      "          [0.0173, 0.3942, 0.6989, 0.1777, 0.8026, 0.6657],\n",
      "          [0.8115, 0.1408, 0.9803, 0.0703, 0.5423, 0.6127]],\n",
      "\n",
      "         [[0.7078, 0.7098, 0.2101, 0.2542, 0.6030, 0.5884],\n",
      "          [0.6424, 0.8371, 0.7935, 0.5683, 0.2954, 0.2986],\n",
      "          [0.0946, 0.5144, 0.3284, 0.6188, 0.3014, 0.8973],\n",
      "          [0.4120, 0.1211, 0.2629, 0.7735, 0.6542, 0.2269],\n",
      "          [0.2797, 0.3028, 0.2662, 0.4444, 0.8632, 0.4149]],\n",
      "\n",
      "         [[0.7452, 0.2916, 0.2315, 0.1991, 0.9113, 0.3958],\n",
      "          [0.0679, 0.6578, 0.7525, 0.0667, 0.0019, 0.1343],\n",
      "          [0.8528, 0.9516, 0.0437, 0.8983, 0.2941, 0.0479],\n",
      "          [0.2346, 0.3960, 0.3853, 0.7699, 0.7390, 0.2881],\n",
      "          [0.4765, 0.1048, 0.6108, 0.6040, 0.4855, 0.1226]]],\n",
      "\n",
      "\n",
      "        [[[0.0457, 0.4066, 0.7062, 0.6411, 0.2686, 0.2463],\n",
      "          [0.2084, 0.2501, 0.8574, 0.0247, 0.0448, 0.8278],\n",
      "          [0.5236, 0.0534, 0.7418, 0.9438, 0.8794, 0.3595],\n",
      "          [0.4796, 0.3347, 0.4671, 0.6408, 0.3955, 0.6605],\n",
      "          [0.6574, 0.9376, 0.6486, 0.8962, 0.9246, 0.1067]],\n",
      "\n",
      "         [[0.2294, 0.0353, 0.0377, 0.5959, 0.4406, 0.5857],\n",
      "          [0.1060, 0.1839, 0.9041, 0.1438, 0.0530, 0.1817],\n",
      "          [0.9368, 0.8993, 0.4963, 0.3462, 0.0820, 0.0480],\n",
      "          [0.4179, 0.4892, 0.7880, 0.6291, 0.2573, 0.5040],\n",
      "          [0.6004, 0.5225, 0.0677, 0.2668, 0.8340, 0.8964]],\n",
      "\n",
      "         [[0.1602, 0.2769, 0.3484, 0.4706, 0.6710, 0.8230],\n",
      "          [0.7534, 0.2552, 0.0717, 0.1928, 0.2404, 0.0652],\n",
      "          [0.1516, 0.8037, 0.7761, 0.5781, 0.6223, 0.8312],\n",
      "          [0.2867, 0.5283, 0.7741, 0.2738, 0.3434, 0.6139],\n",
      "          [0.2316, 0.0263, 0.4581, 0.8642, 0.9352, 0.5634]],\n",
      "\n",
      "         [[0.1455, 0.6754, 0.1229, 0.3015, 0.9155, 0.7616],\n",
      "          [0.9797, 0.9942, 0.7507, 0.5255, 0.1346, 0.5897],\n",
      "          [0.2294, 0.0775, 0.3212, 0.0122, 0.9011, 0.5657],\n",
      "          [0.0581, 0.1546, 0.6902, 0.2694, 0.4790, 0.8338],\n",
      "          [0.2780, 0.2774, 0.6892, 0.7075, 0.3894, 0.8623]]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a random tensor of size 3x4\n",
    "random_tensor = torch.rand(3)\n",
    "print(random_tensor,\"\\n\")\n",
    "random_tensor = torch.rand(3, 4)\n",
    "print(random_tensor,\"\\n\")\n",
    "random_tensor = torch.rand(3, 4, 5)\n",
    "print(random_tensor,\"\\n\")\n",
    "random_tensor = torch.rand(3, 4, 5, 6)\n",
    "print(random_tensor,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 224, 224]), 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a random tensor with similar shape to an image tensor\n",
    "random_tensor_image_size_tensor = torch.randn(size=(3,224, 224)) #height, width, color channels(R, G, B)\n",
    "# random_tensor_image_size_tensor = torch.randn(3,224, 224) #height, width, color channels(R, G, B)\n",
    "random_tensor_image_size_tensor.shape, random_tensor_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zeros and Ones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# Create a ensors of all zeros\n",
    "zero = torch.zeros(3,4)\n",
    "print(zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor = torch.rand(3,4)\n",
    "print(zero*random_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.ones(4, 4)\n",
    "print(ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Range of tensors and tensors-like objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])\n",
      "tensor([ 0, 11, 22, 33, 44, 55, 66, 77])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DHUSNIC INFANT DM\\AppData\\Local\\Temp\\ipykernel_19344\\3818570455.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  one_to_ten = torch.range(1, 10)\n"
     ]
    }
   ],
   "source": [
    "# use torch.range()\n",
    "one_to_ten = torch.range(1, 10)\n",
    "print(one_to_ten)\n",
    "one_to_ten = torch.arange(start= 0, end=78, step=11)\n",
    "print(one_to_ten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Creating a tensor like\n",
    "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
    "print(ten_zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor datatypes\n",
    "#### Defnitions\n",
    "\n",
    "There are many different [tensor datatypes available in PyTorch](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "\n",
    "Some are specific for CPU and some are better for GPU.\n",
    "\n",
    "Getting to know which one can take some time.\n",
    "\n",
    "Generally if you see `torch.cuda` anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
    "\n",
    "The most common type (and generally the default) is `torch.float32` or `torch.float`.\n",
    "\n",
    "This is referred to as \"32-bit floating point\".\n",
    "\n",
    "But there's also 16-bit floating point (`torch.float16` or `torch.half`) and 64-bit floating point (`torch.float64` or `torch.double`).\n",
    "\n",
    "And to confuse things even more there's also 8-bit, 16-bit, 32-bit and 64-bit integers.\n",
    "\n",
    "Plus more!\n",
    "\n",
    "> **Note:** An integer is a flat round number like `7` whereas a float has a decimal `7.0`.\n",
    "1. **check For the correct datatype**\n",
    "2. **check for the correct shape**\n",
    "3. **check for the correct device**\n",
    "\n",
    "\n",
    "The reason for all of these is to do with **precision in computing**.\n",
    "\n",
    "Precision is the amount of detail used to describe a number.\n",
    "\n",
    "The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
    "\n",
    "This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
    "\n",
    "So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate).\n",
    "\n",
    "> **Resources:** \n",
    "  * See the [PyTorch documentation for a list of all available tensor datatypes](https://pytorch.org/docs/stable/tensors.html#data-types).\n",
    "  * Read the [Wikipedia page for an overview of what precision in computing](https://en.wikipedia.org/wiki/Precision_(computer_science)) is.\n",
    "\n",
    "Let's see how to create some tensors with specific datatypes. We can do so using the `dtype` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float16\n",
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "### Float 32 tensor\n",
    "## Important paprameters as dtype, device, and requires_grad\n",
    "float_32_tensor = torch.tensor([1.0, 2.0, 3.0, 4.0],dtype=None)\n",
    "print(float_32_tensor.dtype)\n",
    "float_16_tensor = torch.tensor([1.0, 2.0, 3.0, 4.0],dtype=torch.float16)\n",
    "print(float_16_tensor.dtype)\n",
    "float_64_tensor = torch.tensor([1.0, 2.0, 3.0, 4.0],\n",
    "                               dtype=torch.float64, #What data type is the tensor (e.g. flaoat32, float16, float64, int8, int16, int32, int64, bool)\n",
    "                               device=\"cpu\",        #Where the tensor is stored (e.g. cpu, gpu)\n",
    "                               requires_grad=True   #Whether or not we need to track gradients with this tensor operations (e.g. True, False)\n",
    "                               )\n",
    "\n",
    "print(float_64_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float16\n"
     ]
    }
   ],
   "source": [
    "float_16_tensor = float_64_tensor.type(torch.float16)\n",
    "print(float_16_tensor.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "mult = float_16_tensor*float_32_tensor\n",
    "print(mult.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 6, 9], dtype=torch.int32)\n",
      "tensor([ 9., 36., 81.]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3,6,9],dtype=torch.int32)\n",
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],dtype=torch.float32)\n",
    "print(int_32_tensor)\n",
    "mult = int_32_tensor*float_32_tensor\n",
    "print(mult,mult.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for the Information of Tensor\n",
    "1. **check For the correct datatype**\n",
    "2. **check for the correct shape**\n",
    "3. **check for the correct device**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9563, 0.7839, 0.5575, 0.3343],\n",
      "        [0.2761, 0.0580, 0.0544, 0.1067],\n",
      "        [0.8329, 0.0746, 0.8396, 0.4097]])\n",
      "Datatype of tensor  :   torch.float32\n",
      "Shape of tensor     :   torch.Size([3, 4])\n",
      "Device tensor is on :   cpu\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(3,4)\n",
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor  :   {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor     :   {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on :   {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Manuipulating Tensors (tensor manipulation)**\n",
    "\n",
    "**Tensors are Operations Including**:\n",
    "- Addtion\n",
    "- Subtraction\n",
    "- Multiplication\n",
    "- Division\n",
    "- Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([11, 12, 13])\n",
      "tensor([-9, -8, -7])\n",
      "tensor([10, 20, 30])\n",
      "tensor([0.1000, 0.2000, 0.3000]) tensor([0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor with a single dimension\n",
    "tensor  = torch.tensor([1, 2, 3])\n",
    "print(tensor)\n",
    "\n",
    "# Tesnsor with Addition, Subtraction, Multiplication\n",
    "print(tensor+10) # Add 10 to each element in the tensor\n",
    "# print(torch.add(tensor, 10)) # Add 10 to each element in the tensor\n",
    "print(tensor-10) # Subtract 10 from each element in the tensor\n",
    "# print(torch.sub(tensor, 10)) # Subtract 10 from each element in the tensor\n",
    "print(tensor*10) # Multiply each element in the tensor by 10\n",
    "# print(torch.mul(tensor, 10)) # Multiply each element in the tensor by 10\n",
    "print(tensor/10,tensor//10) # Divide each element in the tensor by 10\n",
    "# print(torch.div(tensor, 10)) # Divide each element in the tensor by 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) \n",
      " torch.Size([2, 3]) \n",
      "\n",
      "\n",
      " tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]]) \n",
      " torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "### Transpose of a tensor\n",
    "Matrix = torch.tensor([[1,2,3],\n",
    "                       [4,5,6],])\n",
    "\n",
    "print(Matrix,\"\\n\",Matrix.shape,\"\\n\")\n",
    "print(\"\\n\",Matrix.T,\"\\n\",Matrix.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14)\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1.01 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tensor=torch.tensor([1,2,3])\n",
    "print(tensor @ tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X   :   tensor([[0.7396, 0.2467, 0.4329]]) \n",
      "\n",
      "Y   :  tensor([[0.4122],\n",
      "        [0.2511],\n",
      "        [0.4169]]) \n",
      "\n",
      "X * X.T   :   tensor([[0.7953]]) torch.Size([1, 3]) \n",
      "\n",
      "Y * Y.T   :   tensor([[0.1699, 0.1035, 0.1718],\n",
      "        [0.1035, 0.0631, 0.1047],\n",
      "        [0.1718, 0.1047, 0.1738]]) torch.Size([3, 1]) \n",
      "\n",
      "X * Y   :   tensor([[0.5473]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tensor of Matrix Multiplication\n",
    "X = torch.rand(1,3)\n",
    "print(f\"X   :   {X}\",\"\\n\")\n",
    "Y = torch.rand(3, 1)\n",
    "print(f\"Y   :  {Y}\",\"\\n\")\n",
    "print(f\"X * X.T   :   {torch.matmul(X,X.T)}\",X.shape,\"\\n\") # Matrix Multiplication\n",
    "print(f\"Y * Y.T   :   {torch.matmul(Y,Y.T)}\",Y.shape,\"\\n\") # Matrix Multiplication\n",
    "print(f\"X * Y   :   {X.mm(Y)}\",\"\\n\") # Matrix Multiplication\n",
    "# print(f\"X * Y   :   {torch.mm(X, Y)}\",\"\\n\") # Matrix Multiplication\n",
    "# print(f\"X * Y   :   {X @ Y}\",\"\\n\") # Matrix Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One of the most Common errors in deep learning is the \"Shape Mismatch\" error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) torch.Size([3, 2]) \n",
      "\n",
      "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)\n",
      "tensor_A @ tensor_B.T :   \n",
      " tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n"
     ]
    }
   ],
   "source": [
    "### Shapes for Matrix Multiplication\n",
    "tensor_A  = torch.tensor([[1,2],\n",
    "                          [3,4],\n",
    "                          [5,6]])\n",
    "tensor_B  = torch.tensor([[7,10],\n",
    "                          [8,11],\n",
    "                          [9,12]])\n",
    "print(tensor_A.shape, tensor_B.shape,\"\\n\")\n",
    "try:\n",
    "    print(f\"tensor_A @ tensor_B :  \",\"\\n\",tensor_A @ tensor_B)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f\"tensor_A @ tensor_B.T :  \",\"\\n\",tensor_A @ tensor_B.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Aggregation of Tensors\n",
    "- Min\n",
    "- Max\n",
    "- Mean\n",
    "- Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]) torch.Size([10])\n",
      "Min of tesnsor: 0\n",
      "Max of tesnsor: 90\n",
      "Sum of tesnsor: 450\n",
      "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long \n",
      " But its  torch.int64 \n",
      "\n",
      "Mean of tesnsor: 45.0\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.arange(0,100,10)\n",
    "print(tensor , tensor.shape)\n",
    "print(f\"Min of tesnsor: {tensor.min()}\")\n",
    "print(f\"Max of tesnsor: {tensor.max()}\")\n",
    "print(f\"Sum of tesnsor: {tensor.sum()}\")\n",
    "try:\n",
    "    print(f\"Mean of tesnsor: {tensor.mean()}\")\n",
    "except Exception as e:\n",
    "    print(e,\"\\n But its \",tensor.dtype,\"\\n\")\n",
    "    tensor = tensor.type(torch.float32)\n",
    "    print(f\"Mean of tesnsor: {tensor.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Positional Min and Max of a Tensor\n",
    "- Find the position of the maximum and minimum values in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[17,  8, 89, 88,  6, 82, 76, 29, 94, 75]])\n",
      "Position or Index of the Element which has Minimum Value :  4\n",
      "Position or Index of the Element which has Maximum Value :  8\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.randint(1, 100,(1,10))\n",
    "print(tensor)\n",
    "print(f\"Position or Index of the Element which has Minimum Value :  {tensor.argmin()}\")\n",
    "print(f\"Position or Index of the Element which has Maximum Value :  {tensor.argmax()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping, Stacking, Squeezing and Unsqueezing tensors\n",
    "* `Reshaping` - Changing the shape of the tensor to desired shape\n",
    "\n",
    "* `View` - Viewing the tensor as a new shape but keep the same memory as the original tensor\n",
    "\n",
    "* `Stacking` - Combining multiple tensors on top of each other (vstack) or side by side (hstack) or depth wise (dstack)\n",
    "\n",
    "* `Squeezing` - Removing all 1 dimensions from a tensor\n",
    "\n",
    "* `Unsqueezing` - Adding an extra dimension to a tensor\n",
    "\n",
    "* `Permute` - Return a view of the original tensor with its dimensions permuted (swapped) in a certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121, 131,\n",
      "        141, 151, 161, 171, 181, 191]) \n",
      " torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "# Creation of a tensor\n",
    "tensor = torch.arange(1,200,10)\n",
    "print(tensor,\"\\n\",tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,  11,  21,  31,  41,  51,  61,  71,  81,  91],\n",
      "        [101, 111, 121, 131, 141, 151, 161, 171, 181, 191]]) \n",
      " torch.Size([2, 10])\n",
      "tensor([  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121, 131,\n",
      "        141, 151, 161, 171, 181, 191]) \n",
      " torch.Size([20]) \n",
      "\n",
      "tensor([  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121, 131,\n",
      "        141, 151, 161, 171, 181, 191]) \n",
      " torch.Size([20]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reshape the input data\n",
    "tensor_input_reshaped = torch.reshape(tensor, (2,10))\n",
    "print(tensor_input_reshaped, \"\\n\", tensor_input_reshaped.shape)\n",
    "print(tensor, \"\\n\", tensor.shape,\"\\n\")\n",
    "tensor.reshape(2,10)\n",
    "print(tensor, \"\\n\", tensor.shape,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,  11,  21,  31,  41,  51,  61,  71,  81,  91],\n",
      "        [101, 111, 121, 131, 141, 151, 161, 171, 181, 191]]) \n",
      " torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "#Change the View\n",
    "View=tensor.view(2,10)\n",
    "print(View,\"\\n\",View.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121, 131,\n",
      "         141, 151, 161, 171, 181, 191],\n",
      "        [  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121, 131,\n",
      "         141, 151, 161, 171, 181, 191],\n",
      "        [  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101, 111, 121, 131,\n",
      "         141, 151, 161, 171, 181, 191]]) \n",
      " torch.Size([3, 20])\n",
      "tensor([[  1,   1,   1],\n",
      "        [ 11,  11,  11],\n",
      "        [ 21,  21,  21],\n",
      "        [ 31,  31,  31],\n",
      "        [ 41,  41,  41],\n",
      "        [ 51,  51,  51],\n",
      "        [ 61,  61,  61],\n",
      "        [ 71,  71,  71],\n",
      "        [ 81,  81,  81],\n",
      "        [ 91,  91,  91],\n",
      "        [101, 101, 101],\n",
      "        [111, 111, 111],\n",
      "        [121, 121, 121],\n",
      "        [131, 131, 131],\n",
      "        [141, 141, 141],\n",
      "        [151, 151, 151],\n",
      "        [161, 161, 161],\n",
      "        [171, 171, 171],\n",
      "        [181, 181, 181],\n",
      "        [191, 191, 191]]) \n",
      " torch.Size([20, 3])\n",
      "Dimension out of range (expected to be in range of [-2, 1], but got 2)\n"
     ]
    }
   ],
   "source": [
    "### Stack tensors on top of each other, and create a new tensor of size 3x4\n",
    "# vstack=torch.vstack([tensor, tensor, tensor])\n",
    "vstack=torch.stack([tensor, tensor, tensor], dim=0)\n",
    "print(vstack, '\\n', vstack.shape)\n",
    "# vstack=torch.hstack([tensor, tensor, tensor])\n",
    "hstack=torch.stack([tensor, tensor, tensor], dim=1)\n",
    "print(hstack, '\\n', hstack.shape)\n",
    "try:\n",
    "    # vstack=torch.dstack([tensor, tensor, tensor])\n",
    "    dstack=torch.stack([tensor, tensor, tensor], dim=2)\n",
    "    print(dstack, '\\n', dstack.shape)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 2, 1, 2]) \n",
      "\n",
      "torch.Size([2, 2, 2]) \n",
      "\n",
      "torch.Size([2, 1, 2, 1, 2]) \n",
      "\n",
      "torch.Size([2, 2, 1, 2]) \n",
      "\n",
      "Previous tensor: tensor([[7, 7, 8, 1, 4, 2, 7, 3, 7]])\n",
      "Shape Of X: torch.Size([1, 9]) \n",
      "\n",
      "Tensor after squeeze: tensor([7, 7, 8, 1, 4, 2, 7, 3, 7])\n",
      "Shape Of X after squeeze: torch.Size([9])\n"
     ]
    }
   ],
   "source": [
    "# tourch.squeeze() - removes all single dimensions from a target tensor\n",
    "X = torch.zeros(2, 1, 2, 1, 2)\n",
    "print(X.size(),\"\\n\")\n",
    "Y = torch.squeeze(X)\n",
    "print(Y.size(),\"\\n\")\n",
    "Y = torch.squeeze(X, 0)\n",
    "print(Y.size(),\"\\n\")\n",
    "Y = torch.squeeze(X, 1)\n",
    "print(Y.size(),\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "X = torch.randint(1, 10, (1,9))\n",
    "print(f\"Previous tensor: {X}\")\n",
    "print(f\"Shape Of X: {X.shape}\",\"\\n\")\n",
    "print(f\"Tensor after squeeze: {torch.squeeze(X)}\")\n",
    "print(f\"Shape Of X after squeeze: {torch.squeeze(X).shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous target: tensor([1, 2, 3, 4])\n",
      "Previous shape: torch.Size([4]) \n",
      "\n",
      "New target: tensor([[1, 2, 3, 4]])\n",
      "New shape: torch.Size([1, 4]) \n",
      "\n",
      "New target: tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "New shape: torch.Size([4, 1])\n"
     ]
    }
   ],
   "source": [
    "# tourch.unsqueeze() - adds a single dimension to a tensor at a specified dimension\n",
    "X = torch.tensor([1,2,3,4])\n",
    "print(f\"Previous target: {X}\")\n",
    "print(f\"Previous shape: {X.shape}\",\"\\n\")\n",
    "# Add an extra dimension to X\n",
    "X_expanded = X.unsqueeze(dim=0)\n",
    "print(f\"New target: {X_expanded}\")\n",
    "print(f\"New shape: {X_expanded.shape}\",\"\\n\")\n",
    "\n",
    "X_expanded = X.unsqueeze(dim=1)\n",
    "print(f\"New target: {X_expanded}\")\n",
    "print(f\"New shape: {X_expanded.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X : tensor([[[ 2.3702, -1.2116,  0.4407,  0.3191, -0.1280],\n",
      "         [-0.4688, -0.8344, -2.7497, -0.0622, -0.1323],\n",
      "         [ 0.0621, -0.5909, -0.2193, -0.8160, -1.2861]],\n",
      "\n",
      "        [[-1.1370, -0.3983, -2.7680,  1.4871,  1.3792],\n",
      "         [ 1.1238, -0.0144,  0.3005, -0.0344,  1.5291],\n",
      "         [ 1.6074, -0.9067,  1.1236,  0.5800,  0.8567]]])\n",
      "Shape of X : torch.Size([2, 3, 5]) \n",
      "\n",
      "X_permuted : tensor([[[ 2.3702, -0.4688,  0.0621],\n",
      "         [-1.1370,  1.1238,  1.6074]],\n",
      "\n",
      "        [[-1.2116, -0.8344, -0.5909],\n",
      "         [-0.3983, -0.0144, -0.9067]],\n",
      "\n",
      "        [[ 0.4407, -2.7497, -0.2193],\n",
      "         [-2.7680,  0.3005,  1.1236]],\n",
      "\n",
      "        [[ 0.3191, -0.0622, -0.8160],\n",
      "         [ 1.4871, -0.0344,  0.5800]],\n",
      "\n",
      "        [[-0.1280, -0.1323, -1.2861],\n",
      "         [ 1.3792,  1.5291,  0.8567]]])\n",
      "Shape X_permuted : torch.Size([5, 2, 3]) \n",
      "\n",
      "\n",
      "Previous shape: torch.Size([224, 224, 3])\n",
      "New shape: torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# tourch.permute() - to change the order of the dimensions of a tensor\n",
    "X = torch.randn(2, 3, 5)\n",
    "print(f\"X : {X}\")\n",
    "print(f\"Shape of X : {X.shape}\",\"\\n\")\n",
    "X_permuted = X.permute(2, 0, 1)\n",
    "print(f\"X_permuted : {X_permuted}\")\n",
    "print(f\"Shape X_permuted : {X_permuted.shape}\",\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# torch-permute - rearranges the dimensions of a target tensor in a specified order\n",
    "x_original = torch.rand(size=(224, 224, 3)) # [height, width, colour_channels]\n",
    "# Permute the original tensor to rearrange the axis (or dim) order\n",
    "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
    "print(f\"Previous shape: {x_original.shape}\")\n",
    "print(f\"New shape: {x_permuted.shape}\") # [colour channels, height, width]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "- Indexing with PyTourch is similar to indexing with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]]), shape: torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(1, 10).reshape(1,3, 3)\n",
    "print(f\"x: {x}, shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[0] = tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]]) \n",
      "\n",
      "x[0][0] = tensor([1, 2, 3]) \n",
      "\n",
      "x[0][0][0] = 1 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"x[0] = {x[0]}\",\"\\n\")\n",
    "print(f\"x[0][0] = {x[0][0]}\",\"\\n\")\n",
    "print(f\"x[0][0][0] = {x[0][0][0]}\",\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x[0, :] = tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]]) \n",
      "\n",
      "x[:, :, 1] = tensor([[2, 5, 8]])\n"
     ]
    }
   ],
   "source": [
    "# you can also use \":\" to select a all of target dimension\n",
    "print(f\"x[0, :] = {x[0, :]}\",\"\\n\")\n",
    "print(f\"x[:, :, 1] = {x[:,: ,1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6)\n",
      "tensor(9)\n",
      "tensor([[3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Get all vlues of the 0 dimention but only the 1 index value of 1st and 2nd dimention\n",
    "print(x[0,1,2])\n",
    "print(x[0,2,2])\n",
    "print(x[:,:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch tensors & Numpy\n",
    "Numpy is a popular library for scientific computing that uses multi-dimensional arrays and matrices.\n",
    "\n",
    "And because of this , PyTorch has functionality to intract with it.\n",
    "\n",
    "- Data in NumPy , Want in PyTorch tensor\n",
    "- NumPy array -> PyTorch Tensor -> `torch.from_numpy(ndarray)`\n",
    "\n",
    "- PyTorch Tensor -> NumPy array -> `tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array: [1 2 3 4 5]\n",
      "Tensor: tensor([1, 2, 3, 4, 5])\n",
      "Converted Tensor type: torch.int64, Tensor type: torch.int64\n"
     ]
    }
   ],
   "source": [
    "# NumPy array to tensor\n",
    "\n",
    "array = np.array([1, 2, 3, 4, 5])\n",
    "converted_tensor = torch.from_numpy(array)\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(f\"Array: {array}\")\n",
    "print(f\"Tensor: {converted_tensor}\")\n",
    "print(f\"Converted Tensor type: {converted_tensor.dtype}, Tensor type: {tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "numpy_tensor: [[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Tensor to Numpy array\n",
    "tensor  = torch.ones(5, 3)\n",
    "numpy_tensor = tensor.numpy()\n",
    "print(f\"tensor: {tensor}\")\n",
    "print(f\"numpy_tensor: {numpy_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Reproducbility\n",
    "In Short how neural networks are trained\n",
    "\n",
    "`start with a random number -> tensor  operatons -> random number to try and make them of the data -> repeat`\n",
    "\n",
    "- TO Reduce the randomness we can use the concept Called the  **random seed** `torch.manual_seed(seed)`\n",
    "\n",
    "Essentially What the random seed does it \"flavour\" the randomness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5638, 0.7477, 0.3954, 0.0400],\n",
      "        [0.3132, 0.4225, 0.0356, 0.3231],\n",
      "        [0.8651, 0.2833, 0.8869, 0.6871]]) \n",
      "\n",
      "tensor([[0.2623, 0.5016, 0.2028, 0.3039],\n",
      "        [0.7884, 0.5488, 0.4925, 0.7898],\n",
      "        [0.9974, 0.3072, 0.1125, 0.9264]]) \n",
      "\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "print(random_tensor_A,\"\\n\")\n",
    "print(random_tensor_B,\"\\n\")\n",
    "print(random_tensor_A == random_tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor C:\n",
      " tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]]) \n",
      "\n",
      "Random Tensor D:\n",
      " tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]]) \n",
      "\n",
      "Random Tensor SEED :\n",
      " tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets Make some Random but reproducible data\n",
    "RANDOM_SEED=42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "random_tensor_C = torch.rand(3,4)\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "print(f\"Random Tensor C:\\n {random_tensor_C} \\n\")\n",
    "print(f\"Random Tensor D:\\n {random_tensor_D} \\n\")\n",
    "print(f\"Random Tensor SEED :\\n {random_tensor_C == random_tensor_D} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor C:\n",
      " tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]]) \n",
      "\n",
      "Random Tensor D:\n",
      " tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]]) \n",
      "\n",
      "Random Tensor SEED :\n",
      " tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Lets Make some Random but reproducible data\n",
    "RANDOM_SEED=42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3,4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "print(f\"Random Tensor C:\\n {random_tensor_C} \\n\")\n",
    "print(f\"Random Tensor D:\\n {random_tensor_D} \\n\")\n",
    "print(f\"Random Tensor SEED :\\n {random_tensor_C == random_tensor_D} \\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running tensors on GPUs (and making faster computations)\n",
    "\n",
    "- Deep learning algorithms require a lot of numerical operations.\n",
    "\n",
    "- And by default these operations are often done on a CPU (computer processing unit).\n",
    "\n",
    "- However, there's another common piece of hardware called a GPU (graphics processing unit), which is often much faster at performing the specific types of operations neural networks need (matrix multiplications) than CPUs.\n",
    "\n",
    "Your computer might have one.\n",
    "\n",
    "If so, you should look to use it whenever you can to train neural networks because chances are it'll speed up the training time dramatically.\n",
    "\n",
    "There are a few ways to first get access to a GPU and secondly get PyTorch to use the GPU.\n",
    "\n",
    "Note: When I reference \"GPU\" throughout this course, I'm referencing a Nvidia GPU with CUDA enabled (CUDA is a computing platform and API that helps allow GPUs be used for general purpose computing & not just graphics) unless otherwise specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
